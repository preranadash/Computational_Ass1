#CONJUGATE GRADIENT METHOD
import numpy as np

def conjugate_gradient(coefficients, constants, x0=None, tol=1e-2, max_iter=1000):
    n = len(constants)
    if x0 is None:
        x0 = np.zeros(n)

    x = np.copy(x0)
    r = constants - np.dot(coefficients, x)
    p = np.copy(r)
    rs_old = np.dot(r, r)

    for iteration in range(max_iter):
        Ap = np.dot(coefficients, p)
        alpha = rs_old / np.dot(p, Ap)
        x += alpha * p
        r -= alpha * Ap
        rs_new = np.dot(r, r)
        if np.sqrt(rs_new) < tol:
            break
        p = r + (rs_new / rs_old) * p
        rs_old = rs_new

    return x

coefficients = np.array([[0.2, 0.1, 1, 1, 0],
                         [0.1, 4, -1, 1, -1],
                         [ 1, -1, 60, 0, -2],
                         [ 1, 1, 0, 8, 4],
                         [ 0, -1, -2, 4, 700]])

constants = np.array([ 7.859713071, 0.422926408, -0.073592239, -0.540643016, 0.010626163])

solution = conjugate_gradient(coefficients, constants)
print("Solution using Conjugate Gradient method:", solution)
